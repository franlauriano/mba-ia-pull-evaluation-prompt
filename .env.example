# LangSmith Configuration
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=

# Publique um prompt no langsmith hub para gerar seu username, depois abra o prompt e vá no simbolo de cadeado.
USERNAME_LANGSMITH_HUB=

# Prompt a puxar do LangSmith Hub
PROMPT_KEY_PULL_FROM_LANGSMITH_HUB=bug_to_user_story_v1
# Prompt a enviar para o LangSmith Hub
PROMPT_KEY_PUSH_TO_LANGSMITH_HUB=bug_to_user_story_v2

# OpenAI Configuration
OPENAI_API_KEY=

# Google Gemini Configuration
GOOGLE_API_KEY=

# LLM Configuration
LLM_PROVIDER=google
LLM_MODEL=gemini-2.5-flash
EVAL_MODEL=gemini-2.5-flash

#LLM_PROVIDER=openai
#LLM_MODEL=gpt-4o-mini
#EVAL_MODEL=gpt-4o

# Rate limit: delay em segundos entre cada chamada ao LLM no evaluate.py.
EVAL_RATE_LIMIT_DELAY_SECONDS=2

# Prompts a avaliar (opcional). Se alguma estiver preenchida, o evaluate.py usa só essas; senão usa v1 local + v2 Hub.
# Caminho no LangSmith Hub (ex: {USERNAME_LANGSMITH_HUB}/bug_to_user_story_v2)
#EVAL_PROMPT_LANGSMITH=bug_to_user_story_v2
# Caminho do prompt local (YAML). Chave no YAML = nome do arquivo sem extensão, ou use EVAL_PROMPT_LOCAL_KEY
#EVAL_PROMPT_LOCAL_FILE=prompts/bug_to_user_story_v1.yml
#EVAL_PROMPT_LOCAL_KEY=bug_to_user_story_v1